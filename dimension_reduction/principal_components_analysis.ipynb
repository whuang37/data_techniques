{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "Collection of different analyses and codebases for PCA analysis. Works off calculating the covariance across different features to create new axises called principal components which are aggregates of different features. Often used as exploratory analysis to look at data.\n",
    "\n",
    "Uses:\n",
    "- reduce number of dimensions\n",
    "- find patterns\n",
    "- visualize high dimension data\n",
    "- ignore noise\n",
    "- improve classification\n",
    "- capture as much of variance as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Implementation of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def PCA(x, n_components):\n",
    "    \n",
    "    # subtract mean of each variable to center data around origin\n",
    "    x_centered = x - np.mean(x, axis=0)\n",
    "    \n",
    "    # calculate covariance matrix\n",
    "    #    square matrix denoting covariance of each element with one another\n",
    "    cov_mat = np.cov(x_cetnered, rowvar=False)\n",
    "    \n",
    "    # compute eigenvalues and eigenvectors of covariance matrix\n",
    "    #     eigenvectors will represent a different principal axis\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_mat)\n",
    "    \n",
    "    # sort eigenvalues in descending order to arrange eigenvalues in descending order of variability\n",
    "    sorted_index = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvalue = eigenvalues[sorted_index]\n",
    "    sorted_eigenvectors = eigen_vectors[:, sorted_index]\n",
    "    \n",
    "    # select a subset of eigenvectors based on selected components\n",
    "    eigenvector_subset = sorted_eigenvectors[:, 0:n_components]\n",
    "    \n",
    "    # dot product of eigenvector and mean centered data to create a reduced dataset\n",
    "    x_reduced = np.dot(eigenvector_subset.transpose(), x_centered.transpose()).transpose()\n",
    "    \n",
    "    return x_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKlearn Implementation of PCA and Related Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris dataset for testing\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "example_dataset = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = example_dataset\n",
    "# set number of components as needed\n",
    "n_comp = 2\n",
    "\n",
    "pca = PCA(n_components=n_comp)\n",
    "\n",
    "principal_components = pca.fit_transform(df)\n",
    "\n",
    "column_names = [f\"PC{i}\" for i in range(1, n_comp+1)]\n",
    "principal_df = pd.DataFrame(data=principal_components, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
